<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    
    <title>ISSAI'19: From CS to AI</title>
    
    <link rel="stylesheet" href="css/reset.css">
    <link rel="stylesheet" href="css/reveal.css">
    <link rel="stylesheet" href="css/extra.css">
    <link rel="stylesheet" href="css/theme/sky.css">
    
    <!-- Theme used for syntax highlighting of code -->
    <link rel="stylesheet" href="lib/css/monokai.css">
    
    <!-- Printing and PDF exports -->
    <script>
     var link = document.createElement( 'link' );
     link.rel = 'stylesheet';
     link.type = 'text/css';
     link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
     document.getElementsByTagName( 'head' )[0].appendChild( link );
    </script>
  </head>
  <body>
    <div class="reveal">
      <div class="slides">
	<section data-background='https://live.staticflickr.com/65535/48008868668_05e0ca5cec_k_d.jpg'>
	  <h1>From CS and engineering to AI</h1>
          <h2>Cloud (and hardware) native AI </h2>
	  <h2><code>@jjmerelo</code></h2>
          <aside class='notes'>This is what I said I was going to talk
    about: From computer science and engineering to AI: cloud native artificial intelligence and artificial life.

            The main theme of this lesson is how cloud computing is
            changing the paradigm of software development to a
            codesign of software and systems (devops) and also to
            several other trends, like serverless computing,
            concurrency and software as a system. This has led to the
            mainstreaming of artificial intelligence (as a service),
            but also to the creation of systems whose very nature is
            stochastic, leading to version of traditional
            metaheuristics that can't rely on static, never-changing
            deployments. We will explain in this lesson how to tap
            these resources, and how to redesign traditional
            metaheuristics, specially evolutionary algorithms, to take
            advantage of them. This is the bridge from Spain to Portugal (or the other way round), it takes people and vehicles from one place to the other... fast. But it was built in 2004; before you probably had to take a ferry or take a roundabout way through Valença do Minho. Same happens with artificial intelligence. You can use the roundabout way that uses general purpose hardware. But, increasingly, you don't need to.
	  </aside> 
        </section>

        <section>
	  <section data-background='https://live.staticflickr.com/5149/5661659306_a73edbfeb3_b_d.jpg'>
	    <h1>13 x 13</h1>

	    <aside class='notes'>This was the size of the first neural network I programmed, back in 1993. I used MS-DOS and C. Do you know why that was the size of the neural net? Because it was what we could fit in 640K (not extended) memory. That was shallow learning for you. Also, resource-bound artificial intelligence. It was a self-organizing map, also called Kohonen's network, and it was used to predict the secondary structure (rough shape) of proteins from their circular dichroism spectrum, basically a vector. More than 1000 citations later, here we are. Main lesson: the most important thing is not the computing power, but to formulate the problem in a way that can be easily solved using artificial intelligence. Computing power is important, but it's not going to increase for ever.</aside>
	  </section>

	  <section data-background='https://live.staticflickr.com/65535/47998722251_b0219b3b19_k_d.jpg'>
	    <h1>What is artificial intelligence?</h1>

	    <aside class='notes'>In those days, there were talks about
	    symbolic and subsymbolic artificial intelligence, as well
	    as different "paths": artificial life and bioinspiration,
	    fuzzy logic and, of course, neural networks. Nowadays all
	    statistical methods whose final objective is related to
	    human senses or capabilities or natural processes are
	    called artificial intelligence.</aside>
	  </section>

	  <section data-background='https://live.staticflickr.com/2143/1576388303_3b60d5c088_o_d.jpg'>
	    <h1>Fast tensor arithmetic</h1>
	    <h2 class='fragment'>Done fast</h2>
	    <aside class='notes'>Multiply-accumulate arrays, or vectors. That's basically it. That is what TensorFlow does, and is the basis of most neural network algorithms. It's floating point arithmetic, but you can also use limited precision if you want.
	    </aside>
	  </section>

	  <section><h1>A bit of TensorFlow: <code>concat</code></h1>
	    <pre><code>if len(values) == 1:
    with ops.name_scope(name) as scope:
      ops.convert_to_tensor(
          axis, name="concat_dim",
          dtype=dtypes.int32).get_shape().assert_is_compatible_with(
              tensor_shape.scalar())
      return identity(values[0], name=scope)
  return gen_array_ops.concat_v2(values=values, axis=axis, name=name)</code></pre>

	    <aside class='notes'>Also, it's in Python. </aside>
	  </section>
	  
          <section><h1>The law stops here</h1>
            <img src='img/f6.jpg' alt="Moore's law and beyond">
            <aside class='notes'>Taken from <a href='https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext'>Hennesy
		and Patterson's article</a> on the golden era of computer
              architecture. Today Moore's prediction is 15 times bigger
              than actual density. So this calls for new solutions for
              today's computing and power hungry applications.</aside>
          </section>

          <section
            data-background='https://live.staticflickr.com/65535/47986811256_b39a3043fe_k_d.jpg'><h1>Improvements
            in</h1>
            <h2 class='fragment'>software architecture</h2>
            <h2 class='fragment'>hardware architecture</h2>
          </section>

          <section
          data-background='https://live.staticflickr.com/1900/44257273412_56e89091f1_k_d.jpg'><h1>Through
            the use of free software</h1>
            <h2 class='fragment'>And hardware</h2>
          </section>
        </section>

        <section data-background='https://live.staticflickr.com/65535/40678489883_79e8c8f304_k_d.jpg'>
          <h1>From computer engineering to AI</h1>
	  <aside class='notes'>In this first lesson, we will mainly talk about how improvements in computer architecture are leading the way in higher performance for artificial intelligence workloads</aside>
        </section>
	  

	<!-- Let's start with edge computing -->

        <section>
          <section
          data-background='https://live.staticflickr.com/4902/31993106328_f9b74701d4_k_d.jpg'><h1>Let's
            start at the edge</h1>
          </section>

          <section data-background='img/nvidia-egx.png'>
          <blockquote class='fragment'>NVIDIA Edge Stack is an
        optimized software stack that includes NVIDIA drivers, a CUDA®
        Kubernetes plug-in, a CUDA Docker container runtime, CUDA-X
        libraries, and containerized AI frameworks and
            applications</blockquote>
          <aside class='notes'>Just released last week, taken from <a
        href='https://www.nvidia.com/en-us/data-center/products/egx-edge-computing/'>here</a>. It
        shows the "commoditization" of AI, but also the introduction
        of computing environments that are totally different from your
        average desktop, monolythic environments. You need to know
            stuff.</aside>
          </section>


          <section
            data-background='https://live.staticflickr.com/7849/40203659003_66360c68ae_k_d.jpg'><h1>Edge
            computing</h1>
            
            <aside class='notes'>AI and Edge computing return a
        couple of results in twitter every hour. It's not a trending
        topic, but it's hot. This is the first concept above,
        it's called "Edge stack", it's a "stack" and device for <a href='https://en.wikipedia.org/wiki/Edge_computing'>"edge
              computing"</a>.
              But what is that?</aside>
          </section>

          <section data-background='https://live.staticflickr.com/8674/28106101204_f15a810b08_k_d.jpg'><h2 class='fragment'>Computing
            <strong>below</strong> the clouds</h2>
          </section>

          
          <section><h1>Edge ⇒ distributed, close and user-owned</h1>
            <aside class='notes'>Almost, but not like, traditional
            computing. Except fo rthe fact that is distributed,
            cloud-aware, and in some cases proprietary, it's very
              close to desktop or data-center computing.</aside>
          </section>

          <section><h1>High-performance processing for Internet of
            Things or anything else</h1>
            <aside class='notes'>You probably need to know what's
            Internet of Things. But you probably don't that it's going
              to be BIG</aside>
          </section>

          <section
        data-background='https://www.seeedstudio.site/media/catalog/product/cache/134ea8534034ded9d909870d8862ea94/1/0/102991187-preview_1.png'><h1>Grove
            AI HAT</h1>
            <aside class='notes'>You can buy it for <a
              href='https://www.seeedstudio.com/Grove-AI-HAT-for-Edge-Computing-p-4026.html'>24$</a>
        and use it on your 25$ Raspi, running all kind of AI
              algorithms onsite using free software. HAT → Hardware attached on top.</aside>
          </section>

          <section><h1>5G merges Internet of Things and edge computing</h1>
            <aside class='notes'>Articles such as <a
              href='https://datacenterfrontier.com/5g-accelerating-iartificial-intelligence/'>this
              one</a> talk about city-wide edge computing
              platforms. Some more information: <a
            href='https://www.lemagit.fr/conseil/AI-et-Edge-Computing-un-tandem-gagnant-pour-un-IoT-efficace'>on
              edge and IA</a> and on <a
            href='https://www.darkreading.com/analytics/mist-computing-startup-distributes-security-ai-to-the-network-edge/d/d-id/1334812?_mc=rss_x_drr_edt_aud_dr_x_x-rss-simple'>mist
              computing</a>.</aside>
          </section>

        </section>
        
        <section>

          <section
            data-background='https://live.staticflickr.com/4451/37357490221_35f6292372_o_d.jpg'>
            <h1>And fosters AI chips</h1>
            <h2 class='fragment'><strong>AIS</strong>:
              AI-in-sensor</h2>

            <aside class='notes'>It will arrive in a few years in the
              shape of <a
              href='https://venturebeat.com/2019/02/11/aistorm-raises-13-2-million-for-ai-edge-computing-chips/'>AIStorm</a>
              and other similar chips</aside>
          </section>

          <section><h1>And is fostered by <strong>free
            software</strong></h1>
            <h2 class='fragment'>... And hardware</h2>
          </section>

          <section><h1>Accelerating TensorFlow and Keras</h1>
            <h2 class='fragment'>By using open hardware cores</h2>
          </section>

          <section><h1>Processing tensors</h1>
            <p><a
            href="https://commons.wikimedia.org/wiki/File:Tensor_Processing_Unit_3.0.jpg#/media/File:Tensor_Processing_Unit_3.0.jpg"><img
            src="https://upload.wikimedia.org/wikipedia/commons/b/be/Tensor_Processing_Unit_3.0.jpg"
            alt="Tensor Processing Unit 3.0" width="1960"
            height="1398"></a><br>By <a
            href="//commons.wikimedia.org/w/index.php?title=User:Zinskauf&amp;action=edit&amp;redlink=1"
            class="new" title="User:Zinskauf (page does not
            exist)">Zinskauf</a> - <span class="int-own-work"
            lang="en">Own work</span>, <a
            href="https://creativecommons.org/licenses/by-sa/4.0"
            title="Creative Commons Attribution-Share Alike 4.0">CC
            BY-SA 4.0</a>, <a
              href="https://commons.wikimedia.org/w/index.php?curid=77299254">Link</a></p>
            <aside class='notes'>Un ASIC desarrollado específicamente
            por Google <a
            href='https://en.wikipedia.org/wiki/Tensor_processing_unit'>for
              tensor processing</a>. <a
            href='https://cloud.google.com/blog/products/gcp/an-in-depth-look-at-googles-first-tensor-processing-unit-tpu'>This
              article looks at Google's TPU</a>, which uses a systolic array, but is also called TPU, as in tensor processing unit, a unit specialized in working with tensors.
            </aside>
          </section>

          <section>
            <a href="https://www.researchgate.net/figure/Systolic-array-implementation-of-the-extended-QR-RLS-algorithm_fig1_277814553"><img src="https://www.researchgate.net/profile/Jibanananda_Mehena2/publication/277814553/figure/fig1/AS:391801937645580@1470424269775/Systolic-array-implementation-of-the-extended-QR-RLS-algorithm.png" alt="Systolic array implementation of the extended QR-RLS algorithm"/></a>
	    <aside class='notes'>Systolic array is a new, sometimes asynchronous, dataflow hardware which carries computation in a  non-conventional way.</aside>
          </section>

          <section><h1>RISC-V for the win</h1>
	    <a title="Derrick Coetzee (User:Dcoetzee) [CC0], via Wikimedia Commons" href="https://commons.wikimedia.org/wiki/File:Yunsup_Lee_holding_RISC_V_prototype_chip.jpg"><img width="512" alt="Yunsup Lee holding RISC V prototype chip" src="https://upload.wikimedia.org/wikipedia/commons/thumb/7/7a/Yunsup_Lee_holding_RISC_V_prototype_chip.jpg/512px-Yunsup_Lee_holding_RISC_V_prototype_chip.jpg"></a>
	    <aside class='notes'>Free hardware can be realized any way you want, from an FPGA to an  ASIC to a chip you want someone to print somewhere.This design should be used mainly in auxiliary boards since it does not have a privileged instruction set for supporting operating systems.</aside>
	    </aside>
	  </section>
	  
	  <section data-background='https://i.redd.it/yvy29xpce1i21.png'>
            <h1>Kendryte K210, an AI accelerator</h1>
            <aside class='notes'>Some information <a
            href='https://hackaday.com/2018/10/08/new-part-day-the-risc-v-chip-with-built-in-neural-networks/'>on
              this CPU</a>. SDKs and everything is <a
						      href='https://github.com/kendryte'>in GitHub</a>. This is a dual core Risc-v. Image taken from <a href='https://www.reddit.com/r/Canaan_Creative/comments/atccoa/for_kendryte_k210_information_you_can_visit/'>reddit</a>. Hay implementaciones específicas de Tensorflow para <a href='https://github.com/kendryte/kendryte-tensorflow'>Kendryte</a>
	    </aside>

          </section>

          <section><h1>Or spiking neurons</h1>
            <p><a href="https://commons.wikimedia.org/wiki/File:DARPA_SyNAPSE_16_Chip_Board.jpg#/media/File:DARPA_SyNAPSE_16_Chip_Board.jpg"><img src="https://upload.wikimedia.org/wikipedia/commons/9/9c/DARPA_SyNAPSE_16_Chip_Board.jpg" alt="DARPA SyNAPSE 16 Chip Board.jpg" width="1169" height="648"></a><br>By <a rel="nofollow" class="external text" href="http://www.darpa.mil/Our_Work/DSO/Programs/Systems_of_Neuromorphic_Adaptive_Plastic_Scalable_Electronics_%28SYNAPSE%29.aspx">DARPA SyNAPSE</a> - <a rel="nofollow" class="external free" href="http://www.darpa.mil/NewsEvents/Releases/2014/08/07.aspx">http://www.darpa.mil/NewsEvents/Releases/2014/08/07.aspx</a>, Public Domain, <a href="https://commons.wikimedia.org/w/index.php?curid=34614979">Link</a></p>
            <aside class='notes'>IBM's <a
              href='https://en.wikipedia.org/wiki/TrueNorth'>TrueNorth</a> chip</aside>
          </section>

          <section>
            <h1>Side effect: less energy consumption</h1>
            <h2>+ Less memory footprint, more speed</h2>
          </section>

	  <section><h1>GPUs process vectors... fast</h1>
	    <h2 class='fragment'>As fast as they consume energy</h2>
	  </section>

	  <section><h1>Field programmable gate arrays</h1>
	    <h2 class='fragment'>Software-defined hardware</h2>
	    <h2 class='fragment'><strong>Open hardwaree</strong></h2>
	    <h2 class='fragment'>More bang for the buck</h2>
	    <aside class='notes'>The whole toolchain to program a FPGA, from the toolchain to the board itself, is free software/hardware. There's a company in Granada that manufactures FPGAs able to old up to 8k gates. Check out application of small FPGAs to tensor processing: this article on <a href='https://www.eejournal.com/article/is-ai-the-killer-fpga-application/'>AI, the killer FPGA application</a>
	    </aside>
	  </section>

	  <section data-background='img/FPGA-MMU.svg'>
	    <h1>FPGAs want to be free</h1>
	    <h2>Taken from <a href='https://github.com/jofrfu/tinyTPU'><code>github.com/jofrfu/tinyTPU</code></a></h2>
	    <aside class='notes'>A TPU core that you can use wherever you want. Combine it with RISC-V, if you want.</aside>
          </section>
	  
	  <section><blockquote>Castillo, Pedro Angel, et al. "Evolutionary system for prediction and optimization of hardware architecture performance." 2008 IEEE Congress on Evolutionary Computation (IEEE World Congress on Computational Intelligence). IEEE, 2008.</blockquote>
	    <aside class='notes'>I am in a computer engineering department, and this has to show. This paper also shows that AI (in this case, neural nets) can be used to enhance computer hardware. This is just a brief detour into what we have done in this particular topic.</aside>
	  </section>

	  <section><img src='img/hardware.png' alt='Optimizing through emulation'>
	    <aside class='notes'>This is where we used MLPs to simulate the performance of caches. The basic idea is to create what is called a surrogate model, which approximates the output by simulating it.</aside>
	  </section>
	  
          <section data-background='https://live.staticflickr.com/87/248357911_1a1aa3cca2_o_d.jpg'>
	    <h1>Know the tools</h1>
            <h2 class='fragment'>Understand the concepts</h2>
            <h2 class='fragment'>Build your AI from the bottom</h2>
            <aside class='notes'>Understanding latency, throughput,
            connectivity, routing, energy consumption, the concept of open cores, and all kind of
            engineering and computing problems is essential to
              approach these kind of problems.</aside>
          </section>
          
        </section> <!-- this is the end of the first part -->

        <!-- Let's go up to the cloud -->
        <section>
          
          <section data-background='img/road-to-fuji.jpg'>
            <h1>From computer science to AI</h1>
	    <aside class='notes'>Computing in the cloud is not just computing as usual, taken to a computer that is out there. The concepts are totally and conceptually different.</aside>
          </section>

	  <section data-background='https://live.staticflickr.com/1870/44318581362_aaf64a96dc_k_d.jpg'><h1>Cloud computing ⇒ Working with <strong>virtualized</strong>
              resources</h1>

            <aside class='notes'>These are fake clouds in the Venice
        casino in las Vegas. Cloud resources are virtualized
        resources, not real ones. They belong to someone else,
        too. RMS said "The cloud is someone's else computer", and it's
            mostly true. But you can have your own cloud (or a
            hybrid), too. Virtualizing resources allows you to
        leverage all your infrastructure, or only pay for what you are
        actually using, depending on the model.
          </aside>
          </section>

	  <section data-background='https://live.staticflickr.com/7806/47509366032_aae8a1ae21_k_d.jpg'>
	    <h2>Virtual machines, storage, data stores, message queues, logging, networks, data analysis, identity management...</h2>
	    

	    <aside class='notes'>This means that it's not only virtual machines or storage. There's a whole lot of stuff, at many different conceptual levels.</aside>
	  </section>

          <section data-background='https://live.staticflickr.com/1543/26116201655_c06d273e51_k_d.jpg'><h1><strong>The</strong> current technology for
	  designing, building, testing and deploying
	      applications</h1>

	  </section>

	  <section
	  data-background='https://live.staticflickr.com/7865/47562364091_fcd379e496_k_d.jpg'><h1>Mainframes
	    → Desktop → Servers → Cloud</h1></section>

          <section data-background='https://live.staticflickr.com/7823/46846837534_26f3606bdf_k_d.jpg'><h1>Artificial intelligence needs
	    to <strong>change</strong> with that.</h1>
          </section>
	</section>

	<section data-background='https://live.staticflickr.com/87/241952383_f413b93fdc_o_d.jpg'>
	  <h1>Everything starts with git</h1>
	  <aside class='notes'>Source control systems are not simply a convenience for developing software. They are the backbone of software development in the cloud, using the actions of commits and push as triggers for workflows that eventually end in deployment.</aside>
	</section>
	<section>
          <section
             data-background='https://live.staticflickr.com/7805/32615246827_574b6dbbbd_h_d.jpg'><h1>Infrastructure
              as <strong>code</strong></h1></section>

	  <section><h1>From the simple...</h1>
	    <pre><code>az group create -l westeurope -n CCGroupEU
az vm create -g CCGroupEU -n bobot --image UbuntuLTS
	    </code></pre>

	    <aside class='notes'>Using a simple shell script to tap the API of Azure and create a virtual machine with Ubuntu.</aside>
	  </section>

	  <section><h1>... to the slightly more complex ...</h1>
	    <pre><code>{
    "$schema": "https://schema.management.azure.com/schemas/2015-01-01/deploymentParameters.json#",
    "contentVersion": "1.0.0.0",
    "parameters": {
        "location": { "value": "westeurope"  },
        "accountType": { "value": " Standard_LRS"  },
        "kind": { "value": "StorageV2" },
        "accessTier": { "value": "Cool"   },
        "supportsHttpsTrafficOnly": { "value": true   }
    }
}</code></pre>
	  </section>

	  <section><h1> ... through the more abstract .. </h1>
	    <pre><code>Vagrant.configure("2") do |config|
  config.vm.define 'public' do |public|
    public.vm.box = "debian/stretch64"
    public.vm.network "private_network", ip: "192.168.0.10"
  end
  config.vm.define 'db' do |db|
    db.vm.box = "fnando/dev-xenial64"
    db.vm.network "private_network", ip: "192.168.0.11"
  end
end</code></pre>
	    <aside class='notes'>Vagrant is increasingly used for local deployments, but it's quite useful defining infraestructure in a system-independent way</aside>
	  </section>

	  <section><h1>... to the nuts and bolts ... </h1>
	    <pre><code>- hosts: "{{target}}"
  sudo: yes
  tasks:
    - name: install prerrequisites
      command: apt-get update -y && apt-get upgrade -y
      command: apt-get install aptitude python-apt -y
    - name: install packages
      apt: pkg={{ item}}
      with_items:
        - git 
        - curl 
        - build-essential 
        - libssl-dev
        - nodejs
        - npm
    - name: Create links
      command: ln -s /usr/bin/nodejs /usr/bin/node
      ignore_errors: yes
    - name: Create profile
copy: content="export PAPERTRAIL_PORT={{PAPERTRAIL_PORT}}; export PAPERTRAIL_HOST={{PAPERTRAIL_HOST}}" dest=/home/cloudy/.profile
	    </code></pre> <aside class='notes'>This will not fit in,
	    but gives you an idea of all you can define so that you
	    have infrastructure (services and applications, in this
	      case) defined as code.</aside>

          </section>

	  <section><h1>... to the complex </h1>

	    <pre><code>FROM rabbitmq:latest
LABEL version="0.1" maintainer='jjmerelo@gmail.com'
RUN apt-get update && apt-get upgrade -y && apt-get install -y python3 python3-pip 
RUN update-alternatives --install /usr/bin/python python /usr/bin/python3 1\
    && update-alternatives --install /usr/bin/pip pip /usr/bin/pip3 1
ADD requirements.txt ./
RUN pip3 install --no-cache-dir -r requirements.txt
WORKDIR /home/app
ADD create-user-rmq.sh cliente-con-celery.py PlatziAgenda.py PlatziTareas.py SlackComandos.py PlatziSlack.py ./
RUN mkdir data
ADD data/cursos.json data/cursos.json
CMD ./create-user-rmq.sh && celery -A PlatziTareas worker --loglevel=info & ./cliente-con-celery.py
	    </code></pre>
	  </section>
	</section>

	<section>
	  <section data-background='https://live.staticflickr.com/9/13718651_93c12daa40_o_d.jpg'>
	    <h1>Discrete releases ⇒ Continuous integration/deployments</h1>

	    <aside class='notes'>Describing infraestructure as code allows continuous testing, integration of new features, an deployment. Cycles include the whole team, from systems to test.</aside>
	  </section>
	  
          <section data-background='https://live.staticflickr.com/7890/47557956611_040dbc597e_k_d.jpg'><h1><strong>Idempotent</strong> deployments</h1>
            <aside class='notes'>Explaining <a
        href='https://puppet.com/blog/idempotence-not-just-a-big-and-scary-word'>idempotence
          in cloud deployments</a> and why it matters. </aside>
        </section>

	  <section data-background='https://live.staticflickr.com/5685/20707800708_3fb4009885_k_d.jpg'><h2>Avoiding <em>works-for-me-ism</em></h2>
	      <pre><code>os:
  - linux
services:
  - docker
install:
  - util/travis-build.sh
script:
  - util/travis-test.sh
matrix:
    include:
        - env: BUILDENV=whateverable
        - env: BUILDENV=docker</code></pre>

	      <aside class='notes'>This is just a excerpt of the conf file for the perl 6 language, but shows how continuous integration checks that everything is OK for everyone, before you decide to deploy. You can hook it to GitHub.</aside>
	  </section>
	  
	  <section data-background='https://live.staticflickr.com/7818/40596683963_bf2a4e3d21_k_d.jpg'><h1>DevOps ⇒ Development + QA + Operations</h1>
	  </section>
	</section>

	<section data-background='https://live.staticflickr.com/7832/47513478812_a7eba33ec7_k_d.jpg'>
          <h1>New/old languages on the block</h1>
          <h2 class='fragment'>Go for insfrastructure</h2>
          <h2 class='fragment'>Full-stack Javascript</h2>
        </section>
        
        </section>

        <section>
          <section
          data-background='https://live.staticflickr.com/4855/32138357728_3cd84f40ca_k_d.jpg'>
          <h1><strong>Orchestration</strong> of resources</h1>
          <aside class='notes'>A bit of reading about <a
            href='https://medium.freecodecamp.org/how-to-choose-the-right-container-orchestration-and-how-to-deploy-it-41844021c241'>container orchestration</a></aside>
          </section>

          <section><h2>Kubernetes definition</h2>
            <pre><code>apiVersion: v1
kind: Pod
metadata:
  name: twocontainers
spec:
  containers:
  - name: sise
    image: mhausenblas/simpleservice:0.5.0
    ports:
    - containerPort: 9876
  - name: shell
    image: centos:7
    command:
      - "bin/bash"
      - "-c"
- "sleep 10000"
            </code></pre>
            <aside class='notes'>Taken from
            https://github.com/openshift-evangelists/kbe/blob/master/specs/pods/pod.yaml,
            we need to use kubectl over this to create a deployment;
              you can then use any of the pods to work on.</aside>
          </section>
          
              <section data-background='https://live.staticflickr.com/54/144637792_1a0d2d426e_o_d.jpg'><h1>To create event-based
            architectures</h1></section>
        
        <section data-background='https://live.staticflickr.com/904/40975817774_92c20b5358_k_d.jpg'><h1>Via <strong>distributed</strong>
            configuration</h1>
        </section>

        <section
          data-background='https://live.staticflickr.com/7906/40591935953_05479fa79a_o_d.jpg'><h1>To
            create a <strong>service mesh</strong></h1></section>

        <section data-background='https://live.staticflickr.com/7877/32615538217_f829ed7efe_o_d.jpg'><h1>That includes diverse <strong>levels</strong>
          of virtualization</h1></section>

        <section><h1>And serverless computing</h1>
          <pre><code>module.exports.hello = async (event, context) => {
  return {
    statusCode: 200,
    body: JSON.stringify({
      message: 'Expecto Petronum',
      input: event,
    }),
  };
};</code></pre></section>

        </section>

        <section>
          <section data-background='https://live.staticflickr.com/7912/33487563868_3203f25397_k_d.jpg'><h1><strong>Everything as a service</strong></h1>
            <pre><code>sub MAIN( $subscription-id, $token-json ) {
    my $token = from-json( $token-json.IO.slurp )&lt;access_token>;
    my $ua = HTTP::UserAgent.new;
    $ua.timeout = 10;
    my $res = $ua.get( "https://management.azure.com/subscriptions/$subscription-id/locations?api-version=2016-06-01",
                       Authorization => "Bearer $token",
                       Content-Type => "application/json");
    if $res.is-success { # stuff happens
    } else {
        say "Didn't work: $res";
    }
}</code></pre>
            <aside class='notes'>Meaning you won't have to worry about
          maintaining your service. You will only have to worry about
              paying the bills.</aside>
          </section>

          <section data-background='https://live.staticflickr.com/7851/32440899377_e7da8a9fea_k_d.jpg'>
            <h1>AI as a service</h1>
            <pre><code>const uriBase =
      "https://westcentralus.api.cognitive.microsoft.com/face/v1.0/detect"
    const imageUrl =
      "https://upload.wikimedia.org/wikipedia/commons/3/37/Dagestani_man_and_woman.jpg"
    const params = "?returnFaceAttributes=age,gender,headPose,smile,facialHair," +
        "glasses,emotion,hair,makeup,occlusion,accessories,blur,exposure,noise"
    const uri = uriBase + params
    const imageUrlEnc = "{\"url\":\"" + imageUrl + "\"}"
// .. later 
    req.Header.Add("Content-Type", "application/json") 
    req.Header.Add("Ocp-Apim-Subscription-Key", subscriptionKey)
    resp, err := client.Do(req)
            </code></pre>
            <aside class='notes'>From the most simple like recognizing
            images to the most complex like analyzing feelings or
            creating complex dataflows for processing data in real
            time, the cloud provides programming interfaces to use
              them easily and efficiently. Take example from here: https://docs.microsoft.com/es-es/azure/cognitive-services/face/quickstarts/go</aside>
          </section>
        </section>

        <section data-background='https://live.staticflickr.com/79/237812005_679fb98189_o_d.jpg'><h1>Your next applications will be <strong>born</strong> in the
          cloud</h1>
        </section>
        
        <section
          data-background='https://live.staticflickr.com/1474/25017070362_3ec115d2e5_k_d.jpg'><h1>And
          we need to change <strong>software engineering</strong>
          methods to reflect that</h1>
        </section>

        <section> <!-- Architectures on the cloud -->
        <section
          data-background='https://farm1.staticflickr.com/183/432422744_be08c2ba07_b_d.jpg'>
          <h1>Traditional architectures are monolitic</h1>
		<aside class='notes'>Las aplicaciones habituales son
	      como este monolito. Un tocho, difícilmente escalable,
	      difícilmente desplegable, todo en un mismo ordenador,
	      herramientas súper clásicas. No es que no se pueda usar
	      para trabajar con datos de forma (más o menos) masiva,
		  pero sobre todo por temas de escalado se complica bastante.</aside>
	      </section>

	      <section data-background='img/Edimburgo.jpg'
	               alt='monolito y nubes'>
                <h1>Modern, cloud native architectures are distributed</h1>
		<aside class='notes'>Aquí se ve por un lado el
	      monolito, que vendría a ser la arquitectura clásica, y
	      las nubes, pero están separados unos de otros. Como en <a
	      href='http://www.slideshare.net/jjmerelo/clipboards/data-cloud'>esta
		  transparencia</a>, lo esencial es la separación
	      entre datos y computación y el uso de contenedores y
	      máquinas virtuales, en vez de usar "bare metal" o
		  clusters/grid</aside>
	      </section>

	      <section data-background='img/Oporto.jpg' alt='Nubes negras y sol y todo'>
                <h1>AI computing architectures need to be on the cloud</h1>
		<aside class='notes'><a
		  href='http://www.infoworld.com/article/2905917/big-data/big-data-is-all-about-the-cloud.html'>Big
		  data is all about the cloud</a> y nada más que la
		  nube. Hablar de Hadoop o de OpenStack es perder
		  totalmente de vista el objetivo: crear arquitecturas que
		  se adapten a este ambiente multi-propietario,
		  auto-escalable, efímero y heterogéneo.  </aside>
	      </section>
	      
	      <section data-background='img/cluster.jpg'
	               alt='microservicios'><h1>And based on microservices</h1>
		<aside class='notes'>Por eso hay que aprender
	      arquitecturas como las de microservicios, en los que
	      diferentes procesadores, conectados de forma ligera,
		  procesan los datos compartiendo un bus. Estos
	      "proveedores de servicios" o "procesadores" pueden
	      escalarse fácilmente, desplegarse fácilmente, y
	      adaptarse mucho mejor a un entorno de trabajo de
	      despliegue continuo donde se procesan cientos de datos
	      de cientos de formas diferentes, según su necesidad y su
	      precio.</aside>
	      </section>

	      <section data-background='img/streams.jpg'
	               alt='procesamiento en streams'><h1>Processing streams</h1>
		<aside class='notes'>Procesamiento por flujos, eventos
		  o cosas por el estilo. Se puede combinar
	      perfectamente con lo anterior.</aside>
	      </section>

	      <section
	      data-background='https://farm1.staticflickr.com/165/424839429_a378f13117_b_d.jpg'
alt='troncos y nubes'><h1>Using kappa and other architectures</h1>
		<aside class='notes'>Por ejemplo, la <a
		  href='http://milinda.pathirage.org/kappa-architecture.com/'>arquitectura
	      Kappa</a>, en la que todo es un flujo pero donde el
	      elemento central es el log o registro, es un tipo de
	      arquitectura de procesamiento de datos que se adapta a
	      la nube. Y que hay que ir aprendiendo: Kappa, Kafka, y
	      cosas como Apache Samza o Flink o cosas por el
	      estilo. Nuevas formas de computación, nuevas formas de
		  procesamiento de datos, traídas por la nube,
		  incluyendo <em>big data</em>em> o <em>data as a
	      service</em>, plataformas que ofrecen integración de
	      datos de diferentes fuentes, incluyendo datos
	      abiertos. Por ejemplo, sería interesante integrar los
		  <a href='http://opendata.ugr.es'>datos de la
	      UGR</a>, con los de otras universidades para ver
	      tendencias en investigación o en matriculación en la
	      universidad y ofrecerlo como servicio. </aside>
	      </section>

              <section><img
        src='https://jonboulineau.me/assets/images/kappa_simple.jpg'
        alt='Kappa architecture'>
                <p>Image by <a
                  href='https://www.linkedin.com/pulse/from-lambda-architecture-kappa-using-apache-beam-siddharth-mittal/'>Diddharth
                  Mittal</a></p>
              </section>
        </section>



        <!-- Credits  -->
        <section><h1>Credits</h1>
          <ul class='credits'>
            <li><a
          href='https://www.loc.gov/item/2009631903/'>Suruga-cho from Library of Congress</a></li>
          </ul>
        </section>
        
</div>
</div>

<script src="js/reveal.js"></script>

<script>
  // More info about config & dependencies:
  // - https://github.com/hakimel/reveal.js#configuration
  // - https://github.com/hakimel/reveal.js#dependencies
  Reveal.initialize({
  height: 800,
  width: '95%',
  controls: true,
  progress: true,
  history: true,
  dependencies: [
		     { src: 'plugin/notes/notes.js', async: true },
		     { src: 'plugin/highlight/highlight.js', async: true }
		   ]
		 });
		</script>
	</body>
</html>
